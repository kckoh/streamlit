import streamlit as st
# from langchain.llms import OpenAI
from openai import OpenAI
import os
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()
API_KEY = os.environ['OPENAI_API_KEY']
client= OpenAI()

st.title('ë©‹ì§„ ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ì–´ë³¼ê¹Œìš”?')
st.subheader('_Your Images_ are SO :blue[cool]:star: :sunglasses::heart:')

with st.sidebar:
    """
    ğŸ¤Tip:\n
    _:heart:ì»¨ì…‰ì•„íŠ¸ì¢…ë¥˜_:ê±´ì¶•,ìºë¦­í„°,ë°°ê²½,ë¬´ê¸°ë° ì†Œí’ˆ,ê¸°ê³„ë° ì°¨ëŸ‰,ì• ë‹ˆë©”ì´ì…˜\n
    _:star:ë¸ŒëŸ¬ì‰¬_:ì—°í•„,ì‰í¬,íœ,ì»¬ëŸ¬ì‰í¬,ìˆ˜ì±„,ìœ ì±„,ë¨¹,í…ìŠ¤ì³\n
    _:rose:í™”í’_:ì‚¬ì§„í™”í’,ì¶”ìƒí™”í’,ê³ ì „ëª¨ë˜í™”í’,ì•„ë¥´ëˆ„ë³´í™”í’,ì¸ìƒí™”í’,ë™ì–‘í™”í’,ê·¹ì‚¬ì‹¤í™”í’,íŒì•„íŠ¸í™”í’,ì´ˆí˜„ì‹¤í™”í’,ì ë¬˜í™”í’,í”½ì…€í™”í’

    """


# def generate_images(image_description,num_images):
#     img_response=client.images.generate(
#             model="dall-e-3",
#             prompt=image_description,
#             size="1024x1024",
#             quality="standard",
#             n=1,
              
#             )
#     image_url = img_response.data[0].url
#     return image_url

# img_description=st.text_input( "prompt"  )
# # num_of_images=st.number_input("select",min_value=1,max_value=5,value=1)

# if st.button("Generate Images"):
#     # for _ in range(num_of_images):
#     #     generate_image=generate_images( img_description,num_of_images)
#     #     st.image(generate_image)
#     completion = client.chat.completions.create(
#     model="gpt-3.5-turbo",
#     messages=[
#         {"role": "system", "content": "You are a poetic assistant, skilled in explaining complex programming concepts with creative flair."},
#         {"role": "user", "content": "Compose a poem that explains the concept of recursion in programming."}
#     ]
#     )
#     print(completion.choices[0].message) # Object
#     st.write(completion.choices[0].message.content)
    

if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "ì²œì¬ìŒì•…ê°€ë¡œì„œ , ì•„ë¦„ë‹¤ìš´ ê°€ì‚¬ë¥¼ ë§Œë“¤ì–´ë“œë¦¬ê² ìŠµë‹ˆë‹¤."}]
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

if prompt := st.chat_input():

    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)
    response = client.chat.completions.create(
        model="gpt-3.5-turbo", 
        messages=st.session_state.messages
    )
    msg = response.choices[0].message.content
    st.session_state.messages.append({"role": "assistant", "content": msg})
    st.chat_message("assistant").write(msg)




